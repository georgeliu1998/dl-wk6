{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Analysis with Transformers\n\n","metadata":{}},{"cell_type":"markdown","source":"In this project, we'll use Hugging Face Transformers to do sentiment analysis. In specific, the Rotten Tomatoes dataset from Hugging Face will be used, and we'll use it to fine-tune a pretrained model.","metadata":{}},{"cell_type":"markdown","source":"## Preparation","metadata":{}},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-02-13T04:02:47.573478Z","iopub.execute_input":"2024-02-13T04:02:47.573758Z","iopub.status.idle":"2024-02-13T04:03:02.161808Z","shell.execute_reply.started":"2024-02-13T04:02:47.573732Z","shell.execute_reply":"2024-02-13T04:03:02.160686Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.24.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.12.2)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\nimport torch\nfrom datasets import load_dataset\nimport transformers\nfrom transformers import (\n    pipeline, \n    AutoTokenizer, \n    AutoModelForSequenceClassification, \n    DataCollatorWithPadding,\n    TrainingArguments, \n    Trainer,\n    DistilBertTokenizer, \n    DistilBertForSequenceClassification\n)\n\nfrom huggingface_hub import notebook_login\n\nimport evaluate\n\nseed = 168","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-13T04:03:02.164236Z","iopub.execute_input":"2024-02-13T04:03:02.164937Z","iopub.status.idle":"2024-02-13T04:03:25.508405Z","shell.execute_reply.started":"2024-02-13T04:03:02.164897Z","shell.execute_reply":"2024-02-13T04:03:25.507614Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-02-13 04:03:11.617107: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-13 04:03:11.617281: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-13 04:03:11.793574: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"notebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-02-13T04:03:25.509450Z","iopub.execute_input":"2024-02-13T04:03:25.509968Z","iopub.status.idle":"2024-02-13T04:03:25.531441Z","shell.execute_reply.started":"2024-02-13T04:03:25.509939Z","shell.execute_reply":"2024-02-13T04:03:25.530405Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a165eb6e3e24b3d83c7d70ea55c3b66"}},"metadata":{}}]},{"cell_type":"markdown","source":"## EDA","metadata":{"execution":{"iopub.status.busy":"2024-02-11T16:35:19.766276Z","iopub.execute_input":"2024-02-11T16:35:19.766698Z","iopub.status.idle":"2024-02-11T16:35:21.872366Z","shell.execute_reply.started":"2024-02-11T16:35:19.766666Z","shell.execute_reply":"2024-02-11T16:35:21.870922Z"}}},{"cell_type":"markdown","source":"Below, we'll load in the data using the Datasets library. The dataset is already split into train, validation and test sets, with 8530, 1066 and 1066 samples. \"text\" column is the only feature to use and the task is to predict the label column which has binary lables representing positive and negative sentiments.\n\nWe also obeserve from the data that the classes are almost perfectly balanced, indicating that we can use accuracy as the performance metric. Further, the reviews range in length from several to 250 characters, thus are not particulary long and should be easy to handle.","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"rotten_tomatoes\")\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-02-13T04:03:41.386982Z","iopub.execute_input":"2024-02-13T04:03:41.387845Z","iopub.status.idle":"2024-02-13T04:03:43.609599Z","shell.execute_reply.started":"2024-02-13T04:03:41.387809Z","shell.execute_reply":"2024-02-13T04:03:43.608564Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.89k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ace68671c7ca4e7fb7b612bbccfbb51b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/921 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9eaace4d5014a0abc37eb1eb4e026e8"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset rotten_tomatoes_movie_review/default (download: 476.34 KiB, generated: 1.28 MiB, post-processed: Unknown size, total: 1.75 MiB) to /root/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/488k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00738022219b4bcbb471ac91d6a7dca1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset rotten_tomatoes_movie_review downloaded and prepared to /root/.cache/huggingface/datasets/rotten_tomatoes_movie_review/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32354a513b824954828c22ec182b0125"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 8530\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1066\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1066\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset.set_format(type='pandas')\ndf_train = dataset['train'][:]\ndf_train","metadata":{"execution":{"iopub.status.busy":"2024-02-13T04:03:43.611540Z","iopub.execute_input":"2024-02-13T04:03:43.612542Z","iopub.status.idle":"2024-02-13T04:03:43.648391Z","shell.execute_reply.started":"2024-02-13T04:03:43.612504Z","shell.execute_reply":"2024-02-13T04:03:43.647406Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                   text  label\n0     the rock is destined to be the 21st century's ...      1\n1     the gorgeously elaborate continuation of \" the...      1\n2                        effective but too-tepid biopic      1\n3     if you sometimes like to go to the movies to h...      1\n4     emerges as something rare , an issue movie tha...      1\n...                                                 ...    ...\n8525  any enjoyment will be hinge from a personal th...      0\n8526  if legendary shlockmeister ed wood had ever ma...      0\n8527  hardly a nuanced portrait of a young woman's b...      0\n8528    interminably bleak , to say nothing of boring .      0\n8529  things really get weird , though not particula...      0\n\n[8530 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the rock is destined to be the 21st century's ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the gorgeously elaborate continuation of \" the...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>effective but too-tepid biopic</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>if you sometimes like to go to the movies to h...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>emerges as something rare , an issue movie tha...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8525</th>\n      <td>any enjoyment will be hinge from a personal th...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8526</th>\n      <td>if legendary shlockmeister ed wood had ever ma...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8527</th>\n      <td>hardly a nuanced portrait of a young woman's b...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8528</th>\n      <td>interminably bleak , to say nothing of boring .</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8529</th>\n      <td>things really get weird , though not particula...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8530 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train.label.value_counts(normalize=True).plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2024-02-13T04:03:44.608192Z","iopub.execute_input":"2024-02-13T04:03:44.608898Z","iopub.status.idle":"2024-02-13T04:03:44.813909Z","shell.execute_reply.started":"2024-02-13T04:03:44.608865Z","shell.execute_reply":"2024-02-13T04:03:44.813025Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<Axes: xlabel='label'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"df_train.text.apply(lambda x: len(x)).plot(kind='hist')","metadata":{"execution":{"iopub.status.busy":"2024-02-13T04:03:45.126283Z","iopub.execute_input":"2024-02-13T04:03:45.126983Z","iopub.status.idle":"2024-02-13T04:03:45.372241Z","shell.execute_reply.started":"2024-02-13T04:03:45.126946Z","shell.execute_reply":"2024-02-13T04:03:45.371138Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<Axes: ylabel='Frequency'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"markdown","source":"Below we experiment with different pretrained transformer models. The model is fined tuned using the training set and evaluated on the validation set. Once the final model is chosen, the model is tested on the test set.\n\nFirst we start with the \"distilbert-base-uncased\" model, then swtiched to \"michellejieli/NSFW_text_classifier\", and finanlly used \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\". Also, different values are tested for the weight decay and learning rate hyperparameters.","metadata":{}},{"cell_type":"code","source":"dataset.reset_format()\n\nds_trn, ds_val, ds_tst = dataset['train'], dataset['validation'], dataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-02-13T04:03:49.693916Z","iopub.execute_input":"2024-02-13T04:03:49.694523Z","iopub.status.idle":"2024-02-13T04:03:49.699880Z","shell.execute_reply.started":"2024-02-13T04:03:49.694488Z","shell.execute_reply":"2024-02-13T04:03:49.698968Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-02-12T14:32:18.759629Z","iopub.execute_input":"2024-02-12T14:32:18.760315Z","iopub.status.idle":"2024-02-12T14:32:19.807626Z","shell.execute_reply.started":"2024-02-12T14:32:18.760281Z","shell.execute_reply":"2024-02-12T14:32:19.806700Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d1d8c897bf74835b6018cb186f62567"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7412bde200243399fa68c5a3610923a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93298d8d326648f1ab294944e468cf20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b45c7fe880848159e66946aa9cfbd50"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"text\"], padding=True, truncation=True)\n\nds_trn_tokenized = ds_trn.map(preprocess_function, batched=True)\nds_val_tokenized = ds_val.map(preprocess_function, batched=True)\nds_tst_tokenized = ds_tst.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-12T14:32:22.385602Z","iopub.execute_input":"2024-02-12T14:32:22.385956Z","iopub.status.idle":"2024-02-12T14:32:23.298753Z","shell.execute_reply.started":"2024-02-12T14:32:22.385927Z","shell.execute_reply":"2024-02-12T14:32:23.297899Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7b09f941c6a42d9bf43c7684a3428df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"478f93a24f47404cb6cdcb10a91773c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f0a9d894f414c8b989db0ede6a0ff7f"}},"metadata":{}}]},{"cell_type":"code","source":"accuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-02-12T14:32:44.414339Z","iopub.execute_input":"2024-02-12T14:32:44.414683Z","iopub.status.idle":"2024-02-12T14:32:45.010245Z","shell.execute_reply.started":"2024-02-12T14:32:44.414656Z","shell.execute_reply":"2024-02-12T14:32:45.009311Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad4c21d468e54b5782b0e5e9f3955ade"}},"metadata":{}}]},{"cell_type":"code","source":"id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\nlabel2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert-base-uncased\", \n    num_labels=2, \n    id2label=id2label, \n    label2id=label2id\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-12T14:32:47.582617Z","iopub.execute_input":"2024-02-12T14:32:47.583477Z","iopub.status.idle":"2024-02-12T14:32:49.774784Z","shell.execute_reply.started":"2024-02-12T14:32:47.583440Z","shell.execute_reply":"2024-02-12T14:32:49.773981Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b895bf9226a48f2901577a38d0e9be7"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"trained_model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=8,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n#     report_to='none',\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_trn_tokenized,\n    eval_dataset=ds_val_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:02:15.775611Z","iopub.execute_input":"2024-02-11T21:02:15.776353Z","iopub.status.idle":"2024-02-11T21:09:20.426790Z","shell.execute_reply.started":"2024-02-11T21:02:15.776319Z","shell.execute_reply":"2024-02-11T21:09:20.425620Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2136' max='2136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2136/2136 06:56, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.339044</td>\n      <td>0.843340</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.349500</td>\n      <td>0.361844</td>\n      <td>0.845216</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.349500</td>\n      <td>0.430291</td>\n      <td>0.854597</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.140500</td>\n      <td>0.524861</td>\n      <td>0.857411</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.140500</td>\n      <td>0.656245</td>\n      <td>0.845216</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.056300</td>\n      <td>0.753093</td>\n      <td>0.843340</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.056300</td>\n      <td>0.771190</td>\n      <td>0.847092</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.022900</td>\n      <td>0.788013</td>\n      <td>0.848030</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory trained_model/checkpoint-267 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-801 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1068 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1335 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1602 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2136, training_loss=0.134096723538213, metrics={'train_runtime': 416.5282, 'train_samples_per_second': 163.83, 'train_steps_per_second': 5.128, 'total_flos': 1375673935042560.0, 'train_loss': 0.134096723538213, 'epoch': 8.0})"},"metadata":{}}]},{"cell_type":"code","source":"text = ds_tst[0]['text']\nlabel = ds_tst[0]['label']\ntext, label","metadata":{"execution":{"iopub.status.busy":"2024-02-11T20:48:10.558874Z","iopub.execute_input":"2024-02-11T20:48:10.559238Z","iopub.status.idle":"2024-02-11T20:48:10.567696Z","shell.execute_reply.started":"2024-02-11T20:48:10.559207Z","shell.execute_reply":"2024-02-11T20:48:10.566636Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"('lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .',\n 1)"},"metadata":{}}]},{"cell_type":"code","source":"classifier = pipeline(\"sentiment-analysis\", model=\"georgeliu/trained_model\")\nclassifier(text)","metadata":{"execution":{"iopub.status.busy":"2024-02-11T20:48:14.352552Z","iopub.execute_input":"2024-02-11T20:48:14.352894Z","iopub.status.idle":"2024-02-11T20:48:20.371956Z","shell.execute_reply.started":"2024-02-11T20:48:14.352869Z","shell.execute_reply":"2024-02-11T20:48:20.370164Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98dcc93d45bd4e84ae7ffb7197c8fc58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88fdc0ab3ee64e48baafe156221980ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a9c9455136f4e10851e6f3ddbc9cef4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a3941fb118645daa7309a731b702712"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b049fdd65464768a95ebe04f32612fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f15bbac866a4c6d9b440920a78ab734"}},"metadata":{}},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"[{'label': 'POSITIVE', 'score': 0.9979475140571594}]"},"metadata":{}}]},{"cell_type":"code","source":"text = ds_tst_tokenized[:10]['text']\n\ninputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to('cuda')\n\nwith torch.no_grad():\n    logits = model(**inputs).logits\n    \nlogits","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:15:20.994650Z","iopub.execute_input":"2024-02-11T21:15:20.995354Z","iopub.status.idle":"2024-02-11T21:15:21.026991Z","shell.execute_reply.started":"2024-02-11T21:15:20.995323Z","shell.execute_reply":"2024-02-11T21:15:21.025834Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"tensor([[-1.0467,  0.9836],\n        [-1.7670,  1.8191],\n        [ 0.7557, -0.7334],\n        [-1.7526,  1.7617],\n        [ 0.3621, -0.5309],\n        [-0.0764, -0.0051],\n        [-1.5490,  1.4408],\n        [ 0.4184, -0.4930],\n        [-1.4449,  1.4594],\n        [-1.8321,  1.8692]], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"preds = logits.argmax(axis=1).cpu().numpy()\ntrue_labels = np.array(ds_tst_tokenized[:10]['label'])","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:22:31.560399Z","iopub.execute_input":"2024-02-11T21:22:31.560772Z","iopub.status.idle":"2024-02-11T21:22:31.568925Z","shell.execute_reply.started":"2024-02-11T21:22:31.560745Z","shell.execute_reply":"2024-02-11T21:22:31.567873Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"(preds == true_labels).mean()","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:22:45.907012Z","iopub.execute_input":"2024-02-11T21:22:45.907406Z","iopub.status.idle":"2024-02-11T21:22:45.916914Z","shell.execute_reply.started":"2024-02-11T21:22:45.907374Z","shell.execute_reply":"2024-02-11T21:22:45.915794Z"},"trusted":true},"execution_count":104,"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"0.7"},"metadata":{}}]},{"cell_type":"markdown","source":"Try a different transformer","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:21:09.392682Z","iopub.execute_input":"2024-02-11T21:21:09.393444Z","iopub.status.idle":"2024-02-11T21:21:09.403173Z","shell.execute_reply.started":"2024-02-11T21:21:09.393406Z","shell.execute_reply":"2024-02-11T21:21:09.402008Z"}}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"michellejieli/NSFW_text_classifier\", \n    num_labels=2, \n    id2label=id2label, \n    label2id=label2id\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"trained_model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=8,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n#     report_to='none',\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_trn_tokenized,\n    eval_dataset=ds_val_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:26:28.210341Z","iopub.execute_input":"2024-02-11T21:26:28.211307Z","iopub.status.idle":"2024-02-11T21:33:34.566639Z","shell.execute_reply.started":"2024-02-11T21:26:28.211265Z","shell.execute_reply":"2024-02-11T21:33:34.565424Z"},"trusted":true},"execution_count":107,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faa927a20a7f4f4eb7f8169e1de13d18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41ee55a7d1b6497f88754c090f76a683"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2136' max='2136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2136/2136 06:47, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.386853</td>\n      <td>0.826454</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.428300</td>\n      <td>0.376188</td>\n      <td>0.834897</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.428300</td>\n      <td>0.461067</td>\n      <td>0.834897</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.159700</td>\n      <td>0.547384</td>\n      <td>0.845216</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.159700</td>\n      <td>0.691134</td>\n      <td>0.825516</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.069300</td>\n      <td>0.757261</td>\n      <td>0.837711</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.069300</td>\n      <td>0.811675</td>\n      <td>0.836773</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.029100</td>\n      <td>0.828326</td>\n      <td>0.835835</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory trained_model/checkpoint-267 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-801 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1068 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1335 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1602 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1869 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2136 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n","output_type":"stream"},{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2136, training_loss=0.1619282660636116, metrics={'train_runtime': 408.0131, 'train_samples_per_second': 167.25, 'train_steps_per_second': 5.235, 'total_flos': 1375673935042560.0, 'train_loss': 0.1619282660636116, 'epoch': 8.0})"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", \n    num_labels=2, \n    id2label=id2label, \n    label2id=label2id\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"trained_model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=8,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n#     report_to='none',\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_trn_tokenized,\n    eval_dataset=ds_val_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:36:38.869030Z","iopub.execute_input":"2024-02-11T21:36:38.869703Z","iopub.status.idle":"2024-02-11T21:43:45.183821Z","shell.execute_reply.started":"2024-02-11T21:36:38.869669Z","shell.execute_reply":"2024-02-11T21:43:45.182730Z"},"trusted":true},"execution_count":108,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"466f348d82764e08bad7384c4b5801a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e076af8aa514c05a909965ce2683ee5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2136' max='2136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2136/2136 06:53, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.229149</td>\n      <td>0.915572</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.228300</td>\n      <td>0.276659</td>\n      <td>0.908068</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.228300</td>\n      <td>0.369389</td>\n      <td>0.899625</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.077400</td>\n      <td>0.467416</td>\n      <td>0.903377</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.077400</td>\n      <td>0.582972</td>\n      <td>0.901501</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.026600</td>\n      <td>0.649142</td>\n      <td>0.899625</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.026600</td>\n      <td>0.684988</td>\n      <td>0.901501</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.006500</td>\n      <td>0.694839</td>\n      <td>0.899625</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory trained_model/checkpoint-267 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-801 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1068 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1335 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1602 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1869 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2136 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n","output_type":"stream"},{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2136, training_loss=0.07951939805002695, metrics={'train_runtime': 413.2606, 'train_samples_per_second': 165.126, 'train_steps_per_second': 5.169, 'total_flos': 1375673935042560.0, 'train_loss': 0.07951939805002695, 'epoch': 8.0})"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", \n    num_labels=2, \n    id2label=id2label, \n    label2id=label2id\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"trained_model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=16,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n#     report_to='none',\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_trn_tokenized,\n    eval_dataset=ds_val_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:46:41.809028Z","iopub.execute_input":"2024-02-11T21:46:41.809436Z","iopub.status.idle":"2024-02-11T22:00:38.339261Z","shell.execute_reply.started":"2024-02-11T21:46:41.809404Z","shell.execute_reply":"2024-02-11T22:00:38.338229Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4272' max='4272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4272/4272 13:48, Epoch 16/16]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.229078</td>\n      <td>0.914634</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.227800</td>\n      <td>0.282432</td>\n      <td>0.909944</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.227800</td>\n      <td>0.399891</td>\n      <td>0.895872</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.072300</td>\n      <td>0.491244</td>\n      <td>0.898687</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.072300</td>\n      <td>0.660003</td>\n      <td>0.900563</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.023200</td>\n      <td>0.724354</td>\n      <td>0.905253</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.023200</td>\n      <td>0.746043</td>\n      <td>0.902439</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.004800</td>\n      <td>0.797619</td>\n      <td>0.903377</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.004800</td>\n      <td>0.804541</td>\n      <td>0.904315</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.004700</td>\n      <td>0.828593</td>\n      <td>0.903377</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.004700</td>\n      <td>0.853568</td>\n      <td>0.904315</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.002100</td>\n      <td>0.846136</td>\n      <td>0.904315</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.002100</td>\n      <td>0.860095</td>\n      <td>0.900563</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.003300</td>\n      <td>0.864445</td>\n      <td>0.898687</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.001100</td>\n      <td>0.871718</td>\n      <td>0.902439</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.001100</td>\n      <td>0.874667</td>\n      <td>0.901501</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory trained_model/checkpoint-267 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-801 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1068 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1335 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1602 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1869 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2136 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4272, training_loss=0.03989523862687389, metrics={'train_runtime': 828.5626, 'train_samples_per_second': 164.719, 'train_steps_per_second': 5.156, 'total_flos': 2751241792676040.0, 'train_loss': 0.03989523862687389, 'epoch': 16.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"### Tuen Hyperparams","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", \n    num_labels=2, \n    id2label=id2label, \n    label2id=label2id\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"trained_model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=16,\n    weight_decay=0.02, #double weight decay\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n#     report_to='none',\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_trn_tokenized,\n    eval_dataset=ds_val_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-12T14:34:53.421086Z","iopub.execute_input":"2024-02-12T14:34:53.421988Z","iopub.status.idle":"2024-02-12T14:50:57.380303Z","shell.execute_reply.started":"2024-02-12T14:34:53.421953Z","shell.execute_reply":"2024-02-12T14:50:57.379089Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"962de88e8ad443899f22fb5b4bead30e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"207f67d42f3e4ba2adb598447a1a8d01"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240212_143651-cpi6r9v2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/georgeliu108/huggingface/runs/cpi6r9v2' target=\"_blank\">bright-lantern-2</a></strong> to <a href='https://wandb.ai/georgeliu108/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/georgeliu108/huggingface' target=\"_blank\">https://wandb.ai/georgeliu108/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/georgeliu108/huggingface/runs/cpi6r9v2' target=\"_blank\">https://wandb.ai/georgeliu108/huggingface/runs/cpi6r9v2</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4272' max='4272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4272/4272 13:17, Epoch 16/16]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.229064</td>\n      <td>0.914634</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.227800</td>\n      <td>0.282265</td>\n      <td>0.909944</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.227800</td>\n      <td>0.399654</td>\n      <td>0.896811</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.072300</td>\n      <td>0.489704</td>\n      <td>0.898687</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.072300</td>\n      <td>0.660518</td>\n      <td>0.898687</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.023000</td>\n      <td>0.734916</td>\n      <td>0.903377</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.023000</td>\n      <td>0.740240</td>\n      <td>0.905253</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.005100</td>\n      <td>0.798883</td>\n      <td>0.902439</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.005100</td>\n      <td>0.810185</td>\n      <td>0.906191</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.004100</td>\n      <td>0.853173</td>\n      <td>0.901501</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.004100</td>\n      <td>0.862471</td>\n      <td>0.901501</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.002900</td>\n      <td>0.866146</td>\n      <td>0.902439</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.002900</td>\n      <td>0.883401</td>\n      <td>0.904315</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.002700</td>\n      <td>0.889126</td>\n      <td>0.901501</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.002300</td>\n      <td>0.899497</td>\n      <td>0.902439</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.002300</td>\n      <td>0.902794</td>\n      <td>0.902439</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4272, training_loss=0.03995452179444416, metrics={'train_runtime': 946.7, 'train_samples_per_second': 144.164, 'train_steps_per_second': 4.513, 'total_flos': 2751241792676040.0, 'train_loss': 0.03995452179444416, 'epoch': 16.0})"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", \n    num_labels=2, \n    id2label=id2label, \n    label2id=label2id\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"trained_model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=16,\n    weight_decay=0.06, #increase weight decayn even more\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n#     report_to='none',\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_trn_tokenized,\n    eval_dataset=ds_val_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-12T14:51:25.426085Z","iopub.execute_input":"2024-02-12T14:51:25.426458Z","iopub.status.idle":"2024-02-12T15:04:44.866355Z","shell.execute_reply.started":"2024-02-12T14:51:25.426432Z","shell.execute_reply":"2024-02-12T15:04:44.865358Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4272' max='4272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4272/4272 13:10, Epoch 16/16]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.229071</td>\n      <td>0.914634</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.227900</td>\n      <td>0.282227</td>\n      <td>0.909944</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.227900</td>\n      <td>0.399197</td>\n      <td>0.895872</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.072400</td>\n      <td>0.488451</td>\n      <td>0.899625</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.072400</td>\n      <td>0.662906</td>\n      <td>0.896811</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.023300</td>\n      <td>0.730852</td>\n      <td>0.901501</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.023300</td>\n      <td>0.750276</td>\n      <td>0.902439</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.005100</td>\n      <td>0.776884</td>\n      <td>0.903377</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.005100</td>\n      <td>0.792403</td>\n      <td>0.904315</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.003900</td>\n      <td>0.818650</td>\n      <td>0.904315</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.003900</td>\n      <td>0.845497</td>\n      <td>0.905253</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.002100</td>\n      <td>0.824595</td>\n      <td>0.902439</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.002100</td>\n      <td>0.863896</td>\n      <td>0.902439</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.003800</td>\n      <td>0.852421</td>\n      <td>0.903377</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.001600</td>\n      <td>0.857399</td>\n      <td>0.903377</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.001600</td>\n      <td>0.858216</td>\n      <td>0.902439</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory trained_model/checkpoint-267 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-801 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1068 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1335 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1602 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1869 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2136 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2403 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2670 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2937 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3204 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3471 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3738 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-4005 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-4272 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4272, training_loss=0.03994099950689948, metrics={'train_runtime': 790.5985, 'train_samples_per_second': 172.629, 'train_steps_per_second': 5.404, 'total_flos': 2751241792676040.0, 'train_loss': 0.03994099950689948, 'epoch': 16.0})"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", \n    num_labels=2, \n    id2label=id2label, \n    label2id=label2id\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"trained_model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=16,\n    weight_decay=0.1, #increase weight decayn even more\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n#     report_to='none',\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_trn_tokenized,\n    eval_dataset=ds_val_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:06:44.482637Z","iopub.execute_input":"2024-02-12T15:06:44.483285Z","iopub.status.idle":"2024-02-12T15:20:12.547315Z","shell.execute_reply.started":"2024-02-12T15:06:44.483250Z","shell.execute_reply":"2024-02-12T15:20:12.546382Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4272' max='4272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4272/4272 13:15, Epoch 16/16]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.229106</td>\n      <td>0.914634</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.227900</td>\n      <td>0.282124</td>\n      <td>0.909006</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.227900</td>\n      <td>0.398659</td>\n      <td>0.897749</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.072400</td>\n      <td>0.488253</td>\n      <td>0.900563</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.072400</td>\n      <td>0.663220</td>\n      <td>0.897749</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.023400</td>\n      <td>0.726331</td>\n      <td>0.904315</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.023400</td>\n      <td>0.769138</td>\n      <td>0.902439</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.005500</td>\n      <td>0.785164</td>\n      <td>0.904315</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.005500</td>\n      <td>0.799959</td>\n      <td>0.906191</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.003200</td>\n      <td>0.834503</td>\n      <td>0.904315</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.003200</td>\n      <td>0.855385</td>\n      <td>0.902439</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.002200</td>\n      <td>0.865997</td>\n      <td>0.903377</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.002200</td>\n      <td>0.885358</td>\n      <td>0.900563</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.002800</td>\n      <td>0.882947</td>\n      <td>0.900563</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.001600</td>\n      <td>0.885240</td>\n      <td>0.903377</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.001600</td>\n      <td>0.889493</td>\n      <td>0.903377</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory trained_model/checkpoint-267 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-801 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1068 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1335 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1602 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1869 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2136 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2403 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2670 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2937 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3204 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3471 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3738 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-4005 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-4272 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4272, training_loss=0.03975885882555099, metrics={'train_runtime': 795.3472, 'train_samples_per_second': 171.598, 'train_steps_per_second': 5.371, 'total_flos': 2751241792676040.0, 'train_loss': 0.03975885882555099, 'epoch': 16.0})"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", \n    num_labels=2, \n    id2label=id2label, \n    label2id=label2id\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"trained_model\",\n    learning_rate=2e-4, #increase learning rate\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=16,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n#     report_to='none',\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_trn_tokenized,\n    eval_dataset=ds_val_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:25:36.905787Z","iopub.execute_input":"2024-02-12T15:25:36.906214Z","iopub.status.idle":"2024-02-12T15:39:04.917645Z","shell.execute_reply.started":"2024-02-12T15:25:36.906180Z","shell.execute_reply":"2024-02-12T15:39:04.916314Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4272' max='4272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4272/4272 13:15, Epoch 16/16]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.300292</td>\n      <td>0.876173</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.294600</td>\n      <td>0.539936</td>\n      <td>0.854597</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.294600</td>\n      <td>0.663956</td>\n      <td>0.837711</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.128700</td>\n      <td>0.656737</td>\n      <td>0.848968</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.128700</td>\n      <td>0.815004</td>\n      <td>0.841463</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.060000</td>\n      <td>0.962998</td>\n      <td>0.839587</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.060000</td>\n      <td>1.079449</td>\n      <td>0.837711</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.023000</td>\n      <td>1.047117</td>\n      <td>0.843340</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.023000</td>\n      <td>1.085678</td>\n      <td>0.852720</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.010200</td>\n      <td>1.158861</td>\n      <td>0.846154</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.010200</td>\n      <td>1.199297</td>\n      <td>0.849906</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.005300</td>\n      <td>1.321871</td>\n      <td>0.848968</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.005300</td>\n      <td>1.269129</td>\n      <td>0.849906</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.001100</td>\n      <td>1.276149</td>\n      <td>0.849906</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.001900</td>\n      <td>1.273566</td>\n      <td>0.845216</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.001900</td>\n      <td>1.246134</td>\n      <td>0.847092</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory trained_model/checkpoint-267 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-801 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1068 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1335 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1602 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1869 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2136 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2403 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2670 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2937 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3204 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3471 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3738 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-4005 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-4272 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4272, training_loss=0.06156758411546771, metrics={'train_runtime': 795.7253, 'train_samples_per_second': 171.516, 'train_steps_per_second': 5.369, 'total_flos': 2751241792676040.0, 'train_loss': 0.06156758411546771, 'epoch': 16.0})"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", \n    num_labels=2, \n    id2label=id2label, \n    label2id=label2id\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"trained_model\",\n    learning_rate=2e-6, #reduce learning rate\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=16,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n#     report_to='none',\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_trn_tokenized,\n    eval_dataset=ds_val_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:40:20.636407Z","iopub.execute_input":"2024-02-12T15:40:20.636857Z","iopub.status.idle":"2024-02-12T15:53:42.330351Z","shell.execute_reply.started":"2024-02-12T15:40:20.636825Z","shell.execute_reply":"2024-02-12T15:53:42.328981Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4272' max='4272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4272/4272 13:09, Epoch 16/16]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.275820</td>\n      <td>0.908068</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.327500</td>\n      <td>0.250773</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.327500</td>\n      <td>0.247786</td>\n      <td>0.911820</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.237600</td>\n      <td>0.248846</td>\n      <td>0.912758</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.237600</td>\n      <td>0.251049</td>\n      <td>0.912758</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.218600</td>\n      <td>0.255803</td>\n      <td>0.911820</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.218600</td>\n      <td>0.255105</td>\n      <td>0.912758</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.194600</td>\n      <td>0.258533</td>\n      <td>0.911820</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.194600</td>\n      <td>0.262694</td>\n      <td>0.909944</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.187100</td>\n      <td>0.263872</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.187100</td>\n      <td>0.267080</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.166300</td>\n      <td>0.271007</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.166300</td>\n      <td>0.272507</td>\n      <td>0.909944</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.165500</td>\n      <td>0.274493</td>\n      <td>0.911820</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.158200</td>\n      <td>0.274696</td>\n      <td>0.911820</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.158200</td>\n      <td>0.275399</td>\n      <td>0.911820</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory trained_model/checkpoint-267 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-801 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1068 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1335 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1602 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1869 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2136 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2403 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2670 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2937 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3204 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3471 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3738 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-4005 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-4272 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4272, training_loss=0.20352710677443372, metrics={'train_runtime': 789.5258, 'train_samples_per_second': 172.863, 'train_steps_per_second': 5.411, 'total_flos': 2751241792676040.0, 'train_loss': 0.20352710677443372, 'epoch': 16.0})"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", \n    num_labels=2, \n    id2label=id2label, \n    label2id=label2id\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"trained_model\",\n    learning_rate=2e-7, #reduce learning rate\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=16,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n#     report_to='none',\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_trn_tokenized,\n    eval_dataset=ds_val_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:56:31.937421Z","iopub.execute_input":"2024-02-12T15:56:31.937833Z","iopub.status.idle":"2024-02-12T16:10:07.688920Z","shell.execute_reply.started":"2024-02-12T15:56:31.937803Z","shell.execute_reply":"2024-02-12T16:10:07.687824Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4272' max='4272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4272/4272 13:20, Epoch 16/16]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.456536</td>\n      <td>0.907129</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.492100</td>\n      <td>0.425339</td>\n      <td>0.906191</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.492100</td>\n      <td>0.400295</td>\n      <td>0.909006</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.417200</td>\n      <td>0.378159</td>\n      <td>0.909006</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.417200</td>\n      <td>0.359782</td>\n      <td>0.908068</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.380500</td>\n      <td>0.345173</td>\n      <td>0.908068</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.380500</td>\n      <td>0.333184</td>\n      <td>0.909006</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.339300</td>\n      <td>0.323057</td>\n      <td>0.909006</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.339300</td>\n      <td>0.315095</td>\n      <td>0.909006</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.331600</td>\n      <td>0.308686</td>\n      <td>0.909006</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.331600</td>\n      <td>0.303806</td>\n      <td>0.908068</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.303100</td>\n      <td>0.300144</td>\n      <td>0.909006</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.303100</td>\n      <td>0.297246</td>\n      <td>0.909944</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.304400</td>\n      <td>0.295446</td>\n      <td>0.909944</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.297000</td>\n      <td>0.294329</td>\n      <td>0.909944</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.297000</td>\n      <td>0.293999</td>\n      <td>0.909944</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory trained_model/checkpoint-267 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-801 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1068 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1335 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1602 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1869 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2136 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2403 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2670 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2937 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3204 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3471 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3738 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-4005 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-4272 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4272, training_loss=0.35405352231715054, metrics={'train_runtime': 800.9021, 'train_samples_per_second': 170.408, 'train_steps_per_second': 5.334, 'total_flos': 2751241792676040.0, 'train_loss': 0.35405352231715054, 'epoch': 16.0})"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", \n    num_labels=2, \n    id2label=id2label, \n    label2id=label2id\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"trained_model\",\n    learning_rate=2e-6, #reduce learning rate\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=20, #train for more epochs\n    weight_decay=0.05, #use higher weight decay\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n#     report_to='none',\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_trn_tokenized,\n    eval_dataset=ds_val_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-12T16:10:28.751460Z","iopub.execute_input":"2024-02-12T16:10:28.751830Z","iopub.status.idle":"2024-02-12T16:27:15.714750Z","shell.execute_reply.started":"2024-02-12T16:10:28.751802Z","shell.execute_reply":"2024-02-12T16:27:15.713615Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5340' max='5340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5340/5340 16:40, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.275275</td>\n      <td>0.908068</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.327100</td>\n      <td>0.250594</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.327100</td>\n      <td>0.247583</td>\n      <td>0.911820</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.237000</td>\n      <td>0.248874</td>\n      <td>0.912758</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.237000</td>\n      <td>0.251445</td>\n      <td>0.912758</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.216900</td>\n      <td>0.256591</td>\n      <td>0.911820</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.216900</td>\n      <td>0.255871</td>\n      <td>0.912758</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.191400</td>\n      <td>0.260209</td>\n      <td>0.912758</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.191400</td>\n      <td>0.265658</td>\n      <td>0.911820</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.181700</td>\n      <td>0.267211</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.181700</td>\n      <td>0.271878</td>\n      <td>0.911820</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.158300</td>\n      <td>0.277875</td>\n      <td>0.912758</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.158300</td>\n      <td>0.281116</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.154800</td>\n      <td>0.285023</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.143300</td>\n      <td>0.286638</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.143300</td>\n      <td>0.290313</td>\n      <td>0.909944</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.134900</td>\n      <td>0.293717</td>\n      <td>0.909944</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.134900</td>\n      <td>0.295101</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.132300</td>\n      <td>0.294792</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.132300</td>\n      <td>0.295354</td>\n      <td>0.910882</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory trained_model/checkpoint-267 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-801 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1068 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1335 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1602 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-1869 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2136 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2403 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2670 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-2937 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3204 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3471 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-3738 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-4005 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory trained_model/checkpoint-4272 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5340, training_loss=0.18419504558548946, metrics={'train_runtime': 1000.4625, 'train_samples_per_second': 170.521, 'train_steps_per_second': 5.338, 'total_flos': 3438786400508880.0, 'train_loss': 0.18419504558548946, 'epoch': 20.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Retrain with the tokenizer matching the model\n\npretrained_model = \"distilbert-base-uncased-finetuned-sst-2-english\"\n\ntokenizer = DistilBertTokenizer.from_pretrained(pretrained_model)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\ndef preprocess_function(examples):\n    return tokenizer(examples[\"text\"], padding=True, truncation=True)\n\nds_trn_tokenized = ds_trn.map(preprocess_function, batched=True)\nds_val_tokenized = ds_val.map(preprocess_function, batched=True)\nds_tst_tokenized = ds_tst.map(preprocess_function, batched=True)\n\naccuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)\n\n\nid2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\nlabel2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    pretrained_model, \n    num_labels=2, \n    id2label=id2label, \n    label2id=label2id\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"trained_model\",\n    learning_rate=2e-6, #reduce learning rate\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=20, #train for more epochs\n    weight_decay=0.05, #use higher weight decay\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n#     report_to='none',\n    push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_trn_tokenized,\n    eval_dataset=ds_val_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-13T04:04:05.765177Z","iopub.execute_input":"2024-02-13T04:04:05.765532Z","iopub.status.idle":"2024-02-13T04:22:17.362796Z","shell.execute_reply.started":"2024-02-13T04:04:05.765506Z","shell.execute_reply":"2024-02-13T04:22:17.361892Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df6fa5d09d834606bb49551985558bbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12869cea685246cd9d072afac664a6a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0fc477e826c4739b420227e73004a89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3b2309fa1124f44af548f9d4258a8c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc8c24bd05ce44448b294393eab59c20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f408fcb9d8e4267b2c9bd1d812e41c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de6c1a2f436d42eca28102f3d8906781"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c90e323fd8b41eca05aeade12a0a197"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240213_040441-jldabuy3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/georgeliu108/huggingface/runs/jldabuy3' target=\"_blank\">auspicious-fuse-4</a></strong> to <a href='https://wandb.ai/georgeliu108/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/georgeliu108/huggingface' target=\"_blank\">https://wandb.ai/georgeliu108/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/georgeliu108/huggingface/runs/jldabuy3' target=\"_blank\">https://wandb.ai/georgeliu108/huggingface/runs/jldabuy3</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5340' max='5340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5340/5340 17:00, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.275275</td>\n      <td>0.908068</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.327100</td>\n      <td>0.250594</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.327100</td>\n      <td>0.247583</td>\n      <td>0.911820</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.237000</td>\n      <td>0.248874</td>\n      <td>0.912758</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.237000</td>\n      <td>0.251445</td>\n      <td>0.912758</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.216900</td>\n      <td>0.256591</td>\n      <td>0.911820</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.216900</td>\n      <td>0.255871</td>\n      <td>0.912758</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.191400</td>\n      <td>0.260209</td>\n      <td>0.912758</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.191400</td>\n      <td>0.265658</td>\n      <td>0.911820</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.181700</td>\n      <td>0.267211</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.181700</td>\n      <td>0.271878</td>\n      <td>0.911820</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.158300</td>\n      <td>0.277875</td>\n      <td>0.912758</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.158300</td>\n      <td>0.281116</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.154800</td>\n      <td>0.285023</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.143300</td>\n      <td>0.286638</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.143300</td>\n      <td>0.290313</td>\n      <td>0.909944</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.134900</td>\n      <td>0.293717</td>\n      <td>0.909944</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.134900</td>\n      <td>0.295101</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.132300</td>\n      <td>0.294792</td>\n      <td>0.910882</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.132300</td>\n      <td>0.295354</td>\n      <td>0.910882</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5340, training_loss=0.18419504558548946, metrics={'train_runtime': 1077.3715, 'train_samples_per_second': 158.348, 'train_steps_per_second': 4.957, 'total_flos': 3438786400508880.0, 'train_loss': 0.18419504558548946, 'epoch': 20.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluate Model on Test Set","metadata":{}},{"cell_type":"code","source":"text = ds_tst_tokenized['text']\n\ninputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to('cuda')\n\nwith torch.no_grad():\n    logits = model(**inputs).logits\n    \npreds = logits.argmax(axis=1).cpu().numpy()\ntrue_labels = np.array(ds_tst_tokenized['label'])\n\nacc = (preds == true_labels).mean()","metadata":{"execution":{"iopub.status.busy":"2024-02-13T04:39:53.732156Z","iopub.execute_input":"2024-02-13T04:39:53.732989Z","iopub.status.idle":"2024-02-13T04:39:56.502195Z","shell.execute_reply.started":"2024-02-13T04:39:53.732951Z","shell.execute_reply":"2024-02-13T04:39:56.501174Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(f'Accuracy on test set is {acc :.2%}')","metadata":{"execution":{"iopub.status.busy":"2024-02-13T04:39:56.503981Z","iopub.execute_input":"2024-02-13T04:39:56.504349Z","iopub.status.idle":"2024-02-13T04:39:56.510812Z","shell.execute_reply.started":"2024-02-13T04:39:56.504313Z","shell.execute_reply":"2024-02-13T04:39:56.509803Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Accuracy on test set is 90.24%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Summary","metadata":{}},{"cell_type":"markdown","source":"The finetuned version of distilbert model (\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\") was chosen as the final pretrained model for this project. The model provides a ~6 percentage point performance boost. Learning rate turned out to be the most impactful hyperparameter to tune since it improves the model performance by about 2 percentage points while weight decay hardly changes the model's performance. Clearly, model architecture is the dominating factor in improving model performance. The final performance on the test set is 90.24%. To improve the model's performance further in the future, more pretrained models can be tested, also more hyperparameters can be tuned using more extensive value choices.\n\n\nNOTE: it's discovered after many rounds of training that, the tokenizer was not updated when using different models. Since each model has its own tokenizer, this is problematic and is corrected in the final experiment. But this turned out not to make any difference in the model's performance. This is likely due to the fact the two models are almost the same since one is the fine tuned version of the other, so the tokenizer might also just be the same.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}